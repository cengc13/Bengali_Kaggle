{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vmYpPfCWeSqo",
    "outputId": "60a0d704-1eb5-46bd-831d-67936b4995ea"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x \n",
    "# On Colab, need this to specify tensorflow version\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc, sys\n",
    "import cv2\n",
    "\n",
    "DATA_FOLDER = \"../../data\"\n",
    "directory = \"../tool\"\n",
    "sys.path.append(directory)\n",
    "from utils import (get_n, get_dummies, resize, plot_loss,\n",
    "                     MultiOutputDataGenerator, plot_acc,\n",
    "                     image_from_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4e3lkdL98R3",
    "outputId": "f9aa6149-f6a6-4d8b-b388-ccd1f8614d23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import albumentations as A\n",
    "def cutout_shiftscalerotate(image):\n",
    "    if len(image.shape) > 2:\n",
    "        width, height, _ = image.shape\n",
    "    else:\n",
    "        width, height = image.shape\n",
    "    aug=A.Compose(\n",
    "        [\n",
    "         A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15, \n",
    "        rotate_limit=4, border_mode=cv2.BORDER_REFLECT_101, p=0.6),\n",
    "        A.Cutout(num_holes=1, max_h_size=width//2, max_w_size=height//2,\n",
    "             fill_value=1.0, p=0.4)\n",
    "        ]                     \n",
    "        )\n",
    "    image = aug(image=image)['image']\n",
    "    return image\n",
    "A.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "pmPVGsTqtmeB"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, Activation, Concatenate\n",
    "from tensorflow.keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.__version__\n",
    "# keras.__version__\n",
    "# import matplotlib\n",
    "# matplotlib.__version__\n",
    "# np.__version__\n",
    "# pd.__version__\n",
    "# import sklearn\n",
    "# sklearn.__version__\n",
    "# cv2.__version__\n",
    "# import PIL\n",
    "# PIL.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "nUcfuvJetmeE",
    "outputId": "48f166b1-0685-4d98-c8e2-ed41604ec303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/test_image_data_3.parquet\n",
      "../../data/train.csv\n",
      "../../data/test_image_data_1.parquet\n",
      "../../data/train_image_data_2.parquet\n",
      "../../data/train_image_data_3.parquet\n",
      "../../data/test_image_data_2.parquet\n",
      "../../data/test_image_data_0.parquet\n",
      "../../data/train_image_data_0.parquet\n",
      "../../data/class_map.csv\n",
      "../../data/test.csv\n",
      "../../data/train_image_data_1.parquet\n",
      "../../data/sample_submission.csv\n",
      "../../data/Kalpurush_Fonts/kalpurush-2.ttf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk(DATA_FOLDER):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "FLCyFeHzeSqy"
   },
   "outputs": [],
   "source": [
    "train_df_ = pd.read_csv(DATA_FOLDER+'/train.csv')\n",
    "test_df_ = pd.read_csv(DATA_FOLDER + '/test.csv')\n",
    "class_map_df = pd.read_csv(DATA_FOLDER + '/class_map.csv')\n",
    "sample_sub_df = pd.read_csv(DATA_FOLDER + '/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMEu3e4weSsE"
   },
   "outputs": [],
   "source": [
    "train_df_ = train_df_.drop(['grapheme'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QezeiQzoeSsI"
   },
   "outputs": [],
   "source": [
    "train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4dcHvKyeSsL"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE=128\n",
    "# IMG_SIZE=64\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7T-8Aa8xeSsW"
   },
   "source": [
    "## Densenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNSGpgYCXwvU"
   },
   "outputs": [],
   "source": [
    "def build_densenet(SIZE, rate=0.3):\n",
    "    densenet = DenseNet121(weights='imagenet', include_top=False)\n",
    "\n",
    "    input = Input(shape=(SIZE, SIZE, 1))\n",
    "    x = Conv2D(3, (3, 3), padding='same')(input)\n",
    "    \n",
    "    x = densenet(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # x = BatchNormalization(momentum=0.15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    # x = BatchNormalization(momentum=0.15)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # multi output\n",
    "    grapheme_root = Dense(168, activation = 'softmax', name='root')(x)\n",
    "    vowel_diacritic = Dense(11, activation = 'softmax', name='vowel')(x)\n",
    "    consonant_diacritic = Dense(7, activation = 'softmax', name='consonant')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs=input, outputs=[grapheme_root, vowel_diacritic, consonant_diacritic])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "buNuuRqqAhbY",
    "outputId": "6a842239-0e9e-4070-b9bd-7da3732ea514"
   },
   "outputs": [],
   "source": [
    "# opt = keras.optimizers.RMSprop(learning_rate=lr, rho=0.9)\n",
    "model = build_densenet(SIZE=IMG_SIZE, rate=0.3)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "#               loss_weights=weights,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fMFCfKXf_Ung"
   },
   "outputs": [],
   "source": [
    "# add l1 regularizer into layers \n",
    "regularizer = tf.keras.regularizers.l1(1e-3)\n",
    "for layer in model.layers:\n",
    "    for attr in ['kernel_regularizer']:\n",
    "        if hasattr(layer, attr):\n",
    "            setattr(layer, attr, regularizer)\n",
    "\n",
    "# # set the glorot_normal initializer\n",
    "initializer = keras.initializers.glorot_normal(seed=None)\n",
    "for layer in model.layers:\n",
    "    for attr in ['kernel_initializer']:\n",
    "        if hasattr(layer, attr):\n",
    "            setattr(layer, attr, initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "uXF2gjVSauFD",
    "outputId": "29b119ae-d3d7-4c1b-b02b-72a5234735f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 3)  30          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Model)             multiple             7037504     conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           densenet121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1049600     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "root (Dense)                    (None, 168)          86184       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "vowel (Dense)                   (None, 11)           5643        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "consonant (Dense)               (None, 7)            3591        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,717,592\n",
      "Trainable params: 8,628,824\n",
      "Non-trainable params: 88,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRfPQ7EvYCUt"
   },
   "outputs": [],
   "source": [
    "weights = {'root': 0.4, 'vowel': 0.3, 'consonant':0.3}\n",
    "# lr = 1e-3\n",
    "# opt = keras.optimizers.RMSprop(learning_rate=lr, rho=0.9)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', \n",
    "              loss_weights=weights, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeiKH3tMeSsp"
   },
   "outputs": [],
   "source": [
    "# Learning rate will be half after 3 epochs if accuracy is not increased\n",
    "lr_scheduler = []\n",
    "targets = ['root', 'vowel', 'consonant']\n",
    "for target in targets:\n",
    "    lr_scheduler.append(ReduceLROnPlateau(monitor=f'{target}_accuracy', \n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001))\n",
    "\n",
    "# Callback : Save best model\n",
    "cp = ModelCheckpoint('saved_models/densenet121_168x168.h5',\n",
    "                           monitor = 'val_root_accuracy',\n",
    "                           save_best_only = True,\n",
    "                           save_weights_only = False,\n",
    "                           mode = 'auto',\n",
    "#                            save_freq = 1,\n",
    "                           verbose = 0)\n",
    "# Callback : Early Stop\n",
    "es = EarlyStopping(monitor='val_root_accuracy',\n",
    "                          mode = 'auto',\n",
    "                          patience = 4,\n",
    "                          min_delta = 0,\n",
    "                          verbose = 1)\n",
    "\n",
    "cb = [*lr_scheduler, cp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxFESkKCeSss"
   },
   "outputs": [],
   "source": [
    "# batch_size = 256\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ5cIptnPG6Y"
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"./saved_models/densenet121_168x168.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ5cIptnPG6Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 3)  30          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "densenet121 (Model)             multiple             7037504     conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           densenet121[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1049600     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "root (Dense)                    (None, 168)          86184       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "vowel (Dense)                   (None, 11)           5643        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "consonant (Dense)               (None, 7)            3591        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,717,592\n",
      "Trainable params: 8,628,824\n",
      "Non-trainable params: 88,768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460,
     "referenced_widgets": [
      "dd1d24e5ed624d9e929e839410d12f38",
      "4e93f844feef452cacaecd09c5ba3b6a",
      "e5a7eee15c5348eba4af32a3f3f6bd5b",
      "bb02a4561d5046efa3268e2d5f703bcc",
      "b61c99c4665c4b1d8e0d4c23c95ae742",
      "23acc2628fc7463c95c57a64e3cac421",
      "c0194d42b22f499e92fc68e554394cda",
      "ed74e526301b43e984d869ceb5c0b79c"
     ]
    },
    "colab_type": "code",
    "id": "kS92Hzd4NyB7",
    "outputId": "61b3b6f4-79db-42b8-c6b6-5da0a903a0b6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d2c7ca41b447ffae28f53d2f151f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training images: (50210, 128, 128, 1)\n",
      "Training labels root: (50210, 168)\n",
      "Training labels vowel: (50210, 11)\n",
      "Training labels consonants: (50210, 7)\n",
      "Epoch 1/30\n",
      "721/721 [==============================] - 103s 144ms/step - loss: 1.2314 - root_loss: 2.2599 - vowel_loss: 0.5911 - consonant_loss: 0.5003 - root_accuracy: 0.4772 - vowel_accuracy: 0.8153 - consonant_accuracy: 0.8569 - val_loss: 0.6153 - val_root_loss: 1.1013 - val_vowel_loss: 0.3388 - val_consonant_loss: 0.2439 - val_root_accuracy: 0.6995 - val_vowel_accuracy: 0.8932 - val_consonant_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "646/721 [=========================>....] - ETA: 10s - loss: 0.3954 - root_loss: 0.6861 - vowel_loss: 0.2164 - consonant_loss: 0.1868 - root_accuracy: 0.8051 - vowel_accuracy: 0.9354 - consonant_accuracy: 0.9451"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "# for i in range(4):\n",
    "for i in [0]:\n",
    "# for i in [2,3]:\n",
    "    train_df = pd.merge(pd.read_parquet(DATA_FOLDER + f'/train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id'], axis=1)\n",
    "\n",
    "    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n",
    "    X_train = resize(X_train, size=IMG_SIZE, plain=False)/255\n",
    "\n",
    "    # CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "    X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
    "    X_train.astype(np.float32)\n",
    "\n",
    "    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values.astype(np.uint8)\n",
    "    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values.astype(np.uint8)\n",
    "    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values.astype(np.uint8)\n",
    "\n",
    "    print(f'Training images: {X_train.shape}')\n",
    "    print(f'Training labels root: {Y_train_root.shape}')\n",
    "    print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "    print(f'Training labels consonants: {Y_train_consonant.shape}')\n",
    "\n",
    "    # Divide the data into training and validation set\n",
    "    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = \\\n",
    "    train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=66)\n",
    "    del train_df\n",
    "    del X_train\n",
    "    del Y_train_root, Y_train_vowel, Y_train_consonant\n",
    "\n",
    "    # Data augmentation for creating more training data\n",
    "    datagen = MultiOutputDataGenerator(\n",
    "#         preprocessing_function = cutout_shiftscalerotate\n",
    "        )  # randomly flip images\n",
    "\n",
    "\n",
    "    # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(datagen.flow(x_train, {'root': y_train_root, 'vowel':y_train_vowel, 'consonant': y_train_consonant}, \n",
    "                                batch_size=batch_size),\n",
    "                        epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                        callbacks=cb)\n",
    "\n",
    "    histories.append(history)\n",
    "\n",
    "    # Delete to reduce memory usage\n",
    "    del x_train\n",
    "    del x_test\n",
    "    del y_train_root\n",
    "    del y_test_root\n",
    "    del y_train_vowel\n",
    "    del y_test_vowel\n",
    "    del y_train_consonant\n",
    "    del y_test_consonant\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10N0RMzErax6"
   },
   "outputs": [],
   "source": [
    "model.save(\"./saved_models/densenet121_168x168-2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10N0RMzErax6"
   },
   "outputs": [],
   "source": [
    "# model.save(\"./saved_models/densenet121_96x96_r_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zNpYci4heStF"
   },
   "outputs": [],
   "source": [
    "for dataset in range(2):\n",
    "    plot_loss(histories[dataset], epochs, f'Training Dataset: {dataset}')\n",
    "    plot_acc(histories[dataset], epochs, f'Training Dataset: {dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M34BWB_eStJ"
   },
   "outputs": [],
   "source": [
    "del histories\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai1CP0lpeStL"
   },
   "outputs": [],
   "source": [
    "preds_dict = {\n",
    "    'grapheme_root': [],\n",
    "    'vowel_diacritic': [],\n",
    "    'consonant_diacritic': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9u1XoL9eStO"
   },
   "outputs": [],
   "source": [
    "components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n",
    "target=[] # model predictions placeholder\n",
    "row_id=[] # row_id place holder\n",
    "for i in range(4):\n",
    "    df_test_img = pd.read_parquet(DATA_FOLDER + f'/test_image_data_{i}.parquet') \n",
    "    df_test_img.set_index('image_id', inplace=True)\n",
    "\n",
    "    X_test = resize(df_test_img, size=IMG_SIZE, plain=False, need_progress_bar=False)/255\n",
    "    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    for i, p in enumerate(preds_dict):\n",
    "        preds_dict[p] = np.argmax(preds[i], axis=1)\n",
    "\n",
    "    for k,id in enumerate(df_test_img.index.values):  \n",
    "        for i,comp in enumerate(components):\n",
    "            id_sample=id+'_'+comp\n",
    "            row_id.append(id_sample)\n",
    "            target.append(preds_dict[comp][k])\n",
    "    del df_test_img\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "df_sample = pd.DataFrame(\n",
    "    {\n",
    "        'row_id': row_id,\n",
    "        'target':target\n",
    "    },\n",
    "    columns = ['row_id','target'] \n",
    ")\n",
    "df_sample.to_csv('submission.csv',index=False)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgDzzwtXtmfU"
   },
   "outputs": [],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Densenet121.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23acc2628fc7463c95c57a64e3cac421": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e93f844feef452cacaecd09c5ba3b6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b61c99c4665c4b1d8e0d4c23c95ae742": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bb02a4561d5046efa3268e2d5f703bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed74e526301b43e984d869ceb5c0b79c",
      "placeholder": "​",
      "style": "IPY_MODEL_c0194d42b22f499e92fc68e554394cda",
      "value": "100% 50210/50210 [00:33&lt;00:00, 1518.39it/s]"
     }
    },
    "c0194d42b22f499e92fc68e554394cda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd1d24e5ed624d9e929e839410d12f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5a7eee15c5348eba4af32a3f3f6bd5b",
       "IPY_MODEL_bb02a4561d5046efa3268e2d5f703bcc"
      ],
      "layout": "IPY_MODEL_4e93f844feef452cacaecd09c5ba3b6a"
     }
    },
    "e5a7eee15c5348eba4af32a3f3f6bd5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23acc2628fc7463c95c57a64e3cac421",
      "max": 50210,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b61c99c4665c4b1d8e0d4c23c95ae742",
      "value": 50210
     }
    },
    "ed74e526301b43e984d869ceb5c0b79c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
